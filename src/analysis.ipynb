{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 21:40:47.549131: W external/xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.77. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m\n\u001b[1;32m     28\u001b[0m predictor \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mbuild_transformer_predictor(config\u001b[38;5;241m=\u001b[39mpredictor_config)\n\u001b[1;32m     30\u001b[0m _, return_buckets_values \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_uniform_buckets_edges_values(\n\u001b[1;32m     31\u001b[0m       num_return_buckets\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m params \u001b[38;5;241m=\u001b[39m training_utils\u001b[38;5;241m.\u001b[39mload_parameters(\n\u001b[1;32m     35\u001b[0m     checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/mhamza/searchless_chess/checkpoints/270M\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m     params\u001b[38;5;241m=\u001b[39mpredictor\u001b[38;5;241m.\u001b[39minitial_params(\n\u001b[0;32m---> 37\u001b[0m         rng\u001b[38;5;241m=\u001b[39m\u001b[43mjrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     38\u001b[0m         targets\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint32),\n\u001b[1;32m     39\u001b[0m     ),\n\u001b[1;32m     40\u001b[0m     step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6_400_000\u001b[39m,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m engine \u001b[38;5;241m=\u001b[39m neural_engines\u001b[38;5;241m.\u001b[39mENGINE_FROM_POLICY[policy](\n\u001b[1;32m     44\u001b[0m   return_buckets_values\u001b[38;5;241m=\u001b[39mreturn_buckets_values,\n\u001b[1;32m     45\u001b[0m   predict_fn\u001b[38;5;241m=\u001b[39mneural_engines\u001b[38;5;241m.\u001b[39mwrap_predict_fn(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m   ),\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/random.py:248\u001b[0m, in \u001b[0;36mPRNGKey\u001b[0;34m(seed, impl)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPRNGKey\u001b[39m(seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    223\u001b[0m             impl: PRNGSpecDesc \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m KeyArray:\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Create a legacy PRNG key given an integer seed.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m  This function produces old-style legacy PRNG keys, which are arrays\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    and ``fold_in``.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _return_prng_keys(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43m_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPRNGKey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/random.py:200\u001b[0m, in \u001b[0;36m_key\u001b[0;34m(ctor_name, seed, impl_spec)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(seed):\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accepts a scalar seed, but was given an array of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(seed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != (). Use jax.vmap for batching\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/prng.py:526\u001b[0m, in \u001b[0;36mrandom_seed\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_seed\u001b[39m(seeds: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m typing\u001b[38;5;241m.\u001b[39mArrayLike, impl: PRNGImpl) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PRNGKeyArray:\n\u001b[1;32m    522\u001b[0m   \u001b[38;5;66;03m# Avoid overflow error in X32 mode by first converting ints to int64.\u001b[39;00m\n\u001b[1;32m    523\u001b[0m   \u001b[38;5;66;03m# This breaks JIT invariance for large ints, but supports the common\u001b[39;00m\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;66;03m# use-case of instantiating with Python hashes in X32 mode.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seeds, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 526\u001b[0m     seeds_arr \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m     seeds_arr \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39masarray(seeds)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:5191\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, copy, device)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5190\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(dtype, allow_extended_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:5025\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[1;32m   5023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5024\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input type for array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5025\u001b[0m out_array: Array \u001b[38;5;241m=\u001b[39m \u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_element_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweak_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndmin \u001b[38;5;241m>\u001b[39m ndim(out_array):\n\u001b[1;32m   5028\u001b[0m   out_array \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mexpand_dims(out_array, \u001b[38;5;28mrange\u001b[39m(ndmin \u001b[38;5;241m-\u001b[39m ndim(out_array)))\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/lax/lax.py:585\u001b[0m, in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type, sharding)\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m operand\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_element_type_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m      \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m      \u001b[49m\u001b[43msharding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/lax/lax.py:2865\u001b[0m, in \u001b[0;36m_convert_element_type_bind\u001b[0;34m(operand, new_dtype, weak_type, sharding)\u001b[0m\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_element_type_bind\u001b[39m(operand, \u001b[38;5;241m*\u001b[39m, new_dtype, weak_type, sharding):\n\u001b[0;32m-> 2865\u001b[0m   operand \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_element_type_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweak_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2867\u001b[0m \u001b[43m                                \u001b[49m\u001b[43msharding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2868\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m sharding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2869\u001b[0m     operand \u001b[38;5;241m=\u001b[39m pjit\u001b[38;5;241m.\u001b[39mwith_sharding_constraint(operand, sharding)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/core.py:438\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    436\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    437\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/core.py:442\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[0;32m--> 442\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/core.py:948\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/dispatch.py:90\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     88\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/pjit.py:356\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    354\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 356\u001b[0m outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    359\u001b[0m pgle_profiler \u001b[38;5;241m=\u001b[39m _read_pgle_profiler(jaxpr)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/pjit.py:189\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m   args_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39minit_states, \u001b[38;5;241m*\u001b[39margs_flat]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/core.py:2781\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2777\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2778\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2779\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2780\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/core.py:442\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[0;32m--> 442\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/core.py:948\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/pjit.py:1764\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_extension_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m286\u001b[39m:\n\u001b[1;32m   1756\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m pxla\u001b[38;5;241m.\u001b[39mJitGlobalCppCacheKeys(\n\u001b[1;32m   1757\u001b[0m       donate_argnums\u001b[38;5;241m=\u001b[39mdonated_argnums, donate_argnames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1758\u001b[0m       device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1762\u001b[0m       out_layouts_treedef\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out_layouts_leaves\u001b[38;5;241m=\u001b[39mout_layouts,\n\u001b[1;32m   1763\u001b[0m       use_resource_env\u001b[38;5;241m=\u001b[39mresource_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1764\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcc_shard_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains_explicit_attributes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1769\u001b[0m   has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding_and_layout(\n\u001b[1;32m   1770\u001b[0m       in_shardings, out_shardings, in_layouts, out_layouts, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/pjit.py:1739\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_impl_cache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_):\n\u001b[0;32m-> 1739\u001b[0m   out_flat, compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m      \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m   pgle_profiler \u001b[38;5;241m=\u001b[39m _read_pgle_profiler(jaxpr)\n\u001b[1;32m   1746\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m   1747\u001b[0m       compiled, tree_structure(out_flat), args, out_flat, [], jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m   1748\u001b[0m       jaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;28;01mNone\u001b[39;00m, pgle_profiler)\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/pjit.py:1693\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1685\u001b[0m   distributed_debug_log((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning pjit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md function\u001b[39m\u001b[38;5;124m\"\u001b[39m, name),\n\u001b[1;32m   1686\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_shardings\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_shardings),\n\u001b[1;32m   1687\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_shardings\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_shardings),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1690\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract args\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmap\u001b[39m(xla\u001b[38;5;241m.\u001b[39mabstractify, args)),\n\u001b[1;32m   1691\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfingerprint\u001b[39m\u001b[38;5;124m\"\u001b[39m, fingerprint))\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1693\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsafe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, compiled\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1695\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue  \u001b[38;5;66;03m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:1274\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmut:\n\u001b[1;32m   1273\u001b[0m   args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmut\u001b[38;5;241m.\u001b[39min_mut]\n\u001b[0;32m-> 1274\u001b[0m input_bufs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profiler\u001b[38;5;241m.\u001b[39mPGLEProfiler\u001b[38;5;241m.\u001b[39mtrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpgle_profiler):\n\u001b[1;32m   1276\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_effects \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_unordered_effects\n\u001b[1;32m   1277\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_host_callbacks):\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:1161\u001b[0m, in \u001b[0;36mInputsHandler.__call__\u001b[0;34m(self, input_buffers)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_buffers):\n\u001b[0;32m-> 1161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:120\u001b[0m, in \u001b[0;36mshard_args\u001b[0;34m(shardings, layouts, args, canonicalize)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m canonicalize:\n\u001b[1;32m    119\u001b[0m     arg \u001b[38;5;241m=\u001b[39m xla\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(arg)\n\u001b[0;32m--> 120\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshard_arg_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayouts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# type(arg) -> (list[indices], list[args], list[shardings])\u001b[39;00m\n\u001b[1;32m    123\u001b[0m batches \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: ([], [], [], []))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:202\u001b[0m, in \u001b[0;36m_shard_np_array\u001b[0;34m(xs, shardings, layouts)\u001b[0m\n\u001b[1;32m    200\u001b[0m       indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sharding\u001b[38;5;241m.\u001b[39maddressable_devices_indices_map(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    201\u001b[0m       shards \u001b[38;5;241m=\u001b[39m [x[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m--> 202\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mbatched_device_put\u001b[49m\u001b[43m(\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/conda/envs/searchless_chess/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:227\u001b[0m, in \u001b[0;36mbatched_device_put\u001b[0;34m(aval, sharding, xs, devices, committed)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bufs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(xs):\n\u001b[1;32m    225\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m array\u001b[38;5;241m.\u001b[39mArrayImpl(\n\u001b[1;32m    226\u001b[0m       aval, sharding, bufs, committed\u001b[38;5;241m=\u001b[39mcommitted, _skip_checks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatched_device_put\u001b[49m\u001b[43m(\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommitted\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import searchless_chess.src.transformer as transformer\n",
    "import searchless_chess.src.utils as utils\n",
    "import searchless_chess.src.training_utils as training_utils\n",
    "import searchless_chess.src.engines.neural_engines as neural_engines\n",
    "import searchless_chess.src.tokenizer as tokenizer\n",
    "\n",
    "\n",
    "policy = 'action_value'\n",
    "num_layers = 16\n",
    "embedding_dim = 1024\n",
    "num_heads = 8\n",
    "num_return_buckets = 128\n",
    "output_size = num_return_buckets\n",
    "\n",
    "predictor_config = transformer.TransformerConfig(\n",
    "    vocab_size=utils.NUM_ACTIONS,\n",
    "    output_size=output_size,\n",
    "    pos_encodings=transformer.PositionalEncodings.LEARNED,\n",
    "    max_sequence_length=tokenizer.SEQUENCE_LENGTH + 2,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    embedding_dim=embedding_dim,\n",
    "    apply_post_ln=True,\n",
    "    apply_qk_layernorm=False,\n",
    "    use_causal_mask=False,\n",
    ")\n",
    "\n",
    "predictor = transformer.build_transformer_predictor(config=predictor_config)\n",
    "\n",
    "_, return_buckets_values = utils.get_uniform_buckets_edges_values(\n",
    "      num_return_buckets\n",
    ")\n",
    "\n",
    "params = training_utils.load_parameters(\n",
    "    checkpoint_dir='/home/mhamza/searchless_chess/checkpoints/270M',\n",
    "    params=predictor.initial_params(\n",
    "        rng=jrandom.PRNGKey(1),\n",
    "        targets=np.ones((1, 1), dtype=np.uint32),\n",
    "    ),\n",
    "    step=6_400_000,\n",
    ")\n",
    "\n",
    "engine = neural_engines.ENGINE_FROM_POLICY[policy](\n",
    "  return_buckets_values=return_buckets_values,\n",
    "  predict_fn=neural_engines.wrap_predict_fn(\n",
    "    predictor=predictor,\n",
    "    params=params,\n",
    "    batch_size=1,\n",
    "  ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Blueprint:\n",
      "Number of layers: 16\n",
      "Embedding dimension: 1024\n",
      "Number of heads: 8\n",
      "Output size: 128\n",
      "Vocabulary size: 1968\n",
      "Max sequence length: 79\n",
      "Positional encodings: PositionalEncodings.LEARNED\n",
      "Apply post layer normalization: True\n",
      "Apply QK layer normalization: False\n",
      "Use causal mask: False\n",
      "Other configurations can be added here if needed.\n"
     ]
    }
   ],
   "source": [
    "def print_transformer_blueprint(config):\n",
    "    print(f\"Model Blueprint:\")\n",
    "    print(f\"Number of layers: {config.num_layers}\")\n",
    "    print(f\"Embedding dimension: {config.embedding_dim}\")\n",
    "    print(f\"Number of heads: {config.num_heads}\")\n",
    "    print(f\"Output size: {config.output_size}\")\n",
    "    print(f\"Vocabulary size: {config.vocab_size}\")\n",
    "    print(f\"Max sequence length: {config.max_sequence_length}\")\n",
    "    print(f\"Positional encodings: {config.pos_encodings}\")\n",
    "    print(f\"Apply post layer normalization: {config.apply_post_ln}\")\n",
    "    print(f\"Apply QK layer normalization: {config.apply_qk_layernorm}\")\n",
    "    print(f\"Use causal mask: {config.use_causal_mask}\")\n",
    "    print(f\"Other configurations can be added here if needed.\")\n",
    "\n",
    "# Now call this function to print out the details\n",
    "print_transformer_blueprint(predictor_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Model Layers:\n",
      "Layer: embed/embeddings, Shape: (1968, 1024)\n",
      "Layer: embed_1/embeddings, Shape: (79, 1024)\n",
      "Layer: layer_norm/scale, Shape: (1024,)\n",
      "Layer: layer_norm/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_1/scale, Shape: (1024,)\n",
      "Layer: layer_norm_1/offset, Shape: (1024,)\n",
      "Layer: linear/w, Shape: (1024, 4096)\n",
      "Layer: linear_1/w, Shape: (1024, 4096)\n",
      "Layer: linear_2/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_2/scale, Shape: (1024,)\n",
      "Layer: layer_norm_2/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_1/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_1/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_1/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_1/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_3/scale, Shape: (1024,)\n",
      "Layer: layer_norm_3/offset, Shape: (1024,)\n",
      "Layer: linear_3/w, Shape: (1024, 4096)\n",
      "Layer: linear_4/w, Shape: (1024, 4096)\n",
      "Layer: linear_5/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_4/scale, Shape: (1024,)\n",
      "Layer: layer_norm_4/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_2/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_2/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_2/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_2/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_5/scale, Shape: (1024,)\n",
      "Layer: layer_norm_5/offset, Shape: (1024,)\n",
      "Layer: linear_6/w, Shape: (1024, 4096)\n",
      "Layer: linear_7/w, Shape: (1024, 4096)\n",
      "Layer: linear_8/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_6/scale, Shape: (1024,)\n",
      "Layer: layer_norm_6/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_3/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_3/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_3/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_3/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_7/scale, Shape: (1024,)\n",
      "Layer: layer_norm_7/offset, Shape: (1024,)\n",
      "Layer: linear_9/w, Shape: (1024, 4096)\n",
      "Layer: linear_10/w, Shape: (1024, 4096)\n",
      "Layer: linear_11/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_8/scale, Shape: (1024,)\n",
      "Layer: layer_norm_8/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_4/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_4/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_4/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_4/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_9/scale, Shape: (1024,)\n",
      "Layer: layer_norm_9/offset, Shape: (1024,)\n",
      "Layer: linear_12/w, Shape: (1024, 4096)\n",
      "Layer: linear_13/w, Shape: (1024, 4096)\n",
      "Layer: linear_14/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_10/scale, Shape: (1024,)\n",
      "Layer: layer_norm_10/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_5/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_5/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_5/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_5/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_11/scale, Shape: (1024,)\n",
      "Layer: layer_norm_11/offset, Shape: (1024,)\n",
      "Layer: linear_15/w, Shape: (1024, 4096)\n",
      "Layer: linear_16/w, Shape: (1024, 4096)\n",
      "Layer: linear_17/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_12/scale, Shape: (1024,)\n",
      "Layer: layer_norm_12/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_6/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_6/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_6/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_6/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_13/scale, Shape: (1024,)\n",
      "Layer: layer_norm_13/offset, Shape: (1024,)\n",
      "Layer: linear_18/w, Shape: (1024, 4096)\n",
      "Layer: linear_19/w, Shape: (1024, 4096)\n",
      "Layer: linear_20/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_14/scale, Shape: (1024,)\n",
      "Layer: layer_norm_14/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_7/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_7/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_7/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_7/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_15/scale, Shape: (1024,)\n",
      "Layer: layer_norm_15/offset, Shape: (1024,)\n",
      "Layer: linear_21/w, Shape: (1024, 4096)\n",
      "Layer: linear_22/w, Shape: (1024, 4096)\n",
      "Layer: linear_23/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_16/scale, Shape: (1024,)\n",
      "Layer: layer_norm_16/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_8/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_8/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_8/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_8/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_17/scale, Shape: (1024,)\n",
      "Layer: layer_norm_17/offset, Shape: (1024,)\n",
      "Layer: linear_24/w, Shape: (1024, 4096)\n",
      "Layer: linear_25/w, Shape: (1024, 4096)\n",
      "Layer: linear_26/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_18/scale, Shape: (1024,)\n",
      "Layer: layer_norm_18/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_9/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_9/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_9/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_9/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_19/scale, Shape: (1024,)\n",
      "Layer: layer_norm_19/offset, Shape: (1024,)\n",
      "Layer: linear_27/w, Shape: (1024, 4096)\n",
      "Layer: linear_28/w, Shape: (1024, 4096)\n",
      "Layer: linear_29/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_20/scale, Shape: (1024,)\n",
      "Layer: layer_norm_20/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_10/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_10/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_10/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_10/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_21/scale, Shape: (1024,)\n",
      "Layer: layer_norm_21/offset, Shape: (1024,)\n",
      "Layer: linear_30/w, Shape: (1024, 4096)\n",
      "Layer: linear_31/w, Shape: (1024, 4096)\n",
      "Layer: linear_32/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_22/scale, Shape: (1024,)\n",
      "Layer: layer_norm_22/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_11/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_11/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_11/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_11/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_23/scale, Shape: (1024,)\n",
      "Layer: layer_norm_23/offset, Shape: (1024,)\n",
      "Layer: linear_33/w, Shape: (1024, 4096)\n",
      "Layer: linear_34/w, Shape: (1024, 4096)\n",
      "Layer: linear_35/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_24/scale, Shape: (1024,)\n",
      "Layer: layer_norm_24/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_12/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_12/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_12/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_12/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_25/scale, Shape: (1024,)\n",
      "Layer: layer_norm_25/offset, Shape: (1024,)\n",
      "Layer: linear_36/w, Shape: (1024, 4096)\n",
      "Layer: linear_37/w, Shape: (1024, 4096)\n",
      "Layer: linear_38/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_26/scale, Shape: (1024,)\n",
      "Layer: layer_norm_26/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_13/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_13/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_13/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_13/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_27/scale, Shape: (1024,)\n",
      "Layer: layer_norm_27/offset, Shape: (1024,)\n",
      "Layer: linear_39/w, Shape: (1024, 4096)\n",
      "Layer: linear_40/w, Shape: (1024, 4096)\n",
      "Layer: linear_41/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_28/scale, Shape: (1024,)\n",
      "Layer: layer_norm_28/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_14/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_14/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_14/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_14/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_29/scale, Shape: (1024,)\n",
      "Layer: layer_norm_29/offset, Shape: (1024,)\n",
      "Layer: linear_42/w, Shape: (1024, 4096)\n",
      "Layer: linear_43/w, Shape: (1024, 4096)\n",
      "Layer: linear_44/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_30/scale, Shape: (1024,)\n",
      "Layer: layer_norm_30/offset, Shape: (1024,)\n",
      "Layer: multi_head_dot_product_attention_15/linear/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_15/linear_1/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_15/linear_2/w, Shape: (1024, 1024)\n",
      "Layer: multi_head_dot_product_attention_15/linear_3/w, Shape: (1024, 1024)\n",
      "Layer: layer_norm_31/scale, Shape: (1024,)\n",
      "Layer: layer_norm_31/offset, Shape: (1024,)\n",
      "Layer: linear_45/w, Shape: (1024, 4096)\n",
      "Layer: linear_46/w, Shape: (1024, 4096)\n",
      "Layer: linear_47/w, Shape: (4096, 1024)\n",
      "Layer: layer_norm_32/scale, Shape: (1024,)\n",
      "Layer: layer_norm_32/offset, Shape: (1024,)\n",
      "Layer: linear_48/w, Shape: (1024, 128)\n",
      "Layer: linear_48/b, Shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict(d, parent_key='', sep='/'):\n",
    "    \"\"\"\n",
    "    Custom function to flatten a nested dictionary.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def print_transformer_layers(predictor, config):\n",
    "    # Initialize the model by using the `initial_params` function from the Predictor object\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "\n",
    "    # Create dummy input for initialization\n",
    "    dummy_input = np.ones((1, tokenizer.SEQUENCE_LENGTH + 2), dtype=np.uint32)\n",
    "\n",
    "    # Call the `initial_params` function on the `predictor` object\n",
    "    params = predictor.initial_params(rng, dummy_input)\n",
    "\n",
    "    # Print model structure (flattened dictionary to see all layers)\n",
    "    flattened_params = flatten_dict(params)\n",
    "\n",
    "    print(\"Transformer Model Layers:\")\n",
    "    for layer_name, param_value in flattened_params.items():\n",
    "        print(f\"Layer: {layer_name}, Shape: {param_value.shape}\")\n",
    "\n",
    "# Now call this function to print out the details of your predictor model\n",
    "print_transformer_layers(predictor, predictor_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transformer_decoder_with_intermediate(\n",
    "#     targets: jax.Array,\n",
    "#     config: TransformerConfig,\n",
    "#     capture_intermediates: bool = False,\n",
    "# ) -> tuple:\n",
    "#     \"\"\"Modified transformer decoder to return intermediate outputs.\n",
    "\n",
    "#     Args:\n",
    "#         targets: The integer target values, shape [B, T].\n",
    "#         config: The config to use for the transformer.\n",
    "\n",
    "#     Returns:\n",
    "#         A tuple of (final_logits, layer_outputs), where `final_logits` is the\n",
    "#         output of the model, and `layer_outputs` is a list of the token\n",
    "#         transformations after each layer.\n",
    "#     \"\"\"\n",
    "#     # Right shift the targets to get the inputs (the first token is now a 0).\n",
    "#     inputs = shift_right(targets)\n",
    "\n",
    "#     # Embeds the inputs and adds positional encodings.\n",
    "#     embeddings = embed_sequences(inputs, config)\n",
    "#     h = embeddings\n",
    "    \n",
    "#     # Initialize a list to collect outputs if intermediates are to be captured\n",
    "#     layer_outputs = [h] if capture_intermediates else None\n",
    "\n",
    "#     # Loop through each layer, storing the output after each transformation\n",
    "#     for _ in range(config.num_layers):\n",
    "#         attention_input = layer_norm(h)\n",
    "#         attention = _attention_block(attention_input, config)\n",
    "#         h += attention\n",
    "\n",
    "#         mlp_input = layer_norm(h)\n",
    "#         mlp_output = _mlp_block(mlp_input, config)\n",
    "#         h += mlp_output\n",
    "\n",
    "#         # Append the current output to layer_outputs if capturing intermediates\n",
    "#         if capture_intermediates:\n",
    "#             layer_outputs.append(h)\n",
    "\n",
    "#     if config.apply_post_ln:\n",
    "#         h = layer_norm(h)\n",
    "#     logits = hk.Linear(config.output_size)(h)\n",
    "#     final_logits = jnn.log_softmax(logits, axis=-1)\n",
    "\n",
    "#     # Stack layer_outputs along a new axis if capturing intermediates\n",
    "#     if capture_intermediates:\n",
    "#         layer_outputs = jnp.stack(layer_outputs, axis=0)\n",
    "\n",
    "#     return (final_logits, layer_outputs) if capture_intermediates else final_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# def save_token_transformations_to_csv(predictor, params, input_sequences, output_csv_path):\n",
    "#     \"\"\"Runs the model and saves token transformations after each layer to a CSV file.\n",
    "\n",
    "#     Args:\n",
    "#         predictor: The transformer model predictor.\n",
    "#         params: Model parameters.\n",
    "#         input_sequences: Array of input sequences to process.\n",
    "#         output_csv_path: Path to the CSV file where results will be saved.\n",
    "#     \"\"\"\n",
    "#     # Run the model to get the intermediate outputs\n",
    "#     _, layer_outputs = predictor.predict(params, None, input_sequences)\n",
    "\n",
    "#     # Reshape and prepare data for saving to CSV\n",
    "#     batch_size, seq_length, embedding_dim = input_sequences.shape[0], input_sequences.shape[1], layer_outputs[0].shape[-1]\n",
    "    \n",
    "#     # Flatten layer outputs to a format suitable for CSV\n",
    "#     flattened_outputs = []\n",
    "#     for layer_idx, layer_output in enumerate(layer_outputs):\n",
    "#         for batch_idx in range(batch_size):\n",
    "#             for token_idx in range(seq_length):\n",
    "#                 flattened_row = [layer_idx, batch_idx, token_idx]\n",
    "#                 flattened_row.extend(layer_output[batch_idx, token_idx, :].tolist())\n",
    "#                 flattened_outputs.append(flattened_row)\n",
    "    \n",
    "#     # Save to CSV\n",
    "#     with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "#         csv_writer = csv.writer(csvfile)\n",
    "#         header = [\"Layer\", \"Batch\", \"Token\"] + [f\"Dim_{i}\" for i in range(embedding_dim)]\n",
    "#         csv_writer.writerow(header)\n",
    "#         csv_writer.writerows(flattened_outputs)\n",
    "\n",
    "#     print(f\"Token transformations saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# output_csv_path = 'token_transformations.csv'\n",
    "# input_sequences = np.ones((8, tokenizer.SEQUENCE_LENGTH + 2), dtype=np.uint32)  # Example batch of sequences\n",
    "\n",
    "# predictor = build_transformer_predictor_with_intermediate(predictor_config)\n",
    "# params = predictor.initial_params(jax.random.PRNGKey(0), input_sequences)\n",
    "\n",
    "# save_token_transformations_to_csv(predictor, params, input_sequences, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchless_chess.src.transformer import TransformerConfig, shift_right, embed_sequences, layer_norm, _attention_block, _mlp_block\n",
    "import haiku as hk\n",
    "import jax.nn as jnn\n",
    "from searchless_chess.src import constants\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_decoder_with_intermediate(\n",
    "    targets: jax.Array,\n",
    "    config: TransformerConfig,\n",
    ") -> jax.Array:\n",
    "  \"\"\"Returns the transformer decoder output, shape [B, T, V].\n",
    "\n",
    "  Follows the LLaMa architecture:\n",
    "  https://github.com/facebookresearch/llama/blob/main/llama/model.py\n",
    "  Main changes to the original Transformer decoder:\n",
    "  - Using gating in the MLP block, with SwiGLU activation function.\n",
    "  - Using normalization before the attention and MLP blocks.\n",
    "\n",
    "  Args:\n",
    "    targets: The integer target values, shape [B, T].\n",
    "    config: The config to use for the transformer.\n",
    "  \"\"\"\n",
    "  # Right shift the targets to get the inputs (the first token is now a 0).\n",
    "  # import ipdb; ipdb.set_trace()\n",
    "  inputs = shift_right(targets)\n",
    "  # print(f'inputs.shape: {inputs.shape}')\n",
    "\n",
    "  # Embeds the inputs and adds positional encodings.\n",
    "  embeddings = embed_sequences(inputs, config)\n",
    "  # print(f'embeddings.shape: {embeddings.shape}')\n",
    "  h = embeddings # [B, T, D]\n",
    "  \n",
    "  # List to store the outputs of each layer\n",
    "  # expand dims of the h in the axis 0\n",
    "  layer_outputs = []\n",
    "\n",
    "  for _ in range(config.num_layers):\n",
    "    # record the output of each layer\n",
    "    layer_outputs.append(jnp.expand_dims(h, axis=1)) # [B, 1, T, D]\n",
    "    # print('h.shape:', h.shape)\n",
    "    \n",
    "    attention_input = layer_norm(h)\n",
    "    attention = _attention_block(attention_input, config)\n",
    "    h += attention\n",
    "\n",
    "    mlp_input = layer_norm(h)\n",
    "    mlp_output = _mlp_block(mlp_input, config)\n",
    "    h += mlp_output\n",
    "\n",
    "  if config.apply_post_ln:\n",
    "    h = layer_norm(h)\n",
    "  layer_outputs.append(jnp.expand_dims(h, axis=1)) # [B, 1, T, D]\n",
    "  logits = hk.Linear(config.output_size)(h)\n",
    "  # print(f'logits.shape: {logits.shape}')\n",
    "\n",
    "  # print(f'layer_outputs[0].shape: {layer_outputs[0].shape}')\n",
    "  layer_outputs = jnp.concatenate(layer_outputs, axis=1)\n",
    "  # print(f'layer_outputs.shape: {layer_outputs.shape}')\n",
    "  assert len(layer_outputs.shape) == 4, f\"Expected 4D output, got {layer_outputs.shape}\"\n",
    "\n",
    "  probs = jnn.log_softmax(logits, axis=-1)\n",
    "  return layer_outputs, probs\n",
    "\n",
    "\n",
    "def build_transformer_predictor_with_intermediate(\n",
    "    config: TransformerConfig,\n",
    ") -> constants.Predictor:\n",
    "  \"\"\"Returns a transformer predictor.\"\"\"\n",
    "  model = hk.transform(functools.partial(transformer_decoder_with_intermediate, config=config))\n",
    "  return constants.Predictor(initial_params=model.init, predict=model.apply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.nn as jnn\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "from searchless_chess.src import constants\n",
    "from searchless_chess.src import tokenizer\n",
    "from searchless_chess.src import utils\n",
    "from searchless_chess.src.engines import engine\n",
    "\n",
    "from searchless_chess.src.engines.neural_engines import NeuralEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_scores_with_repetitions(\n",
    "    board: chess.Board,\n",
    "    scores: np.ndarray,\n",
    ") -> None:\n",
    "  \"\"\"Updates the win-probabilities for a board given possible repetitions.\"\"\"\n",
    "  sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
    "  for i, move in enumerate(sorted_legal_moves):\n",
    "    board.push(move)\n",
    "    # If the move results in a draw, associate 50% win prob to it.\n",
    "    if board.is_fivefold_repetition() or board.can_claim_threefold_repetition():\n",
    "      scores[i] = 0.5\n",
    "    board.pop()\n",
    "\n",
    "class ActionValueDebugEngine(NeuralEngine):\n",
    "  \"\"\"Neural engine using a function P(r | s, a).\"\"\"\n",
    "\n",
    "  def analyse(self, board: chess.Board):\n",
    "    \"\"\"Returns buckets log-probs for each action, and FEN.\"\"\"\n",
    "    # Tokenize the legal actions.\n",
    "    sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
    "    legal_actions = [utils.MOVE_TO_ACTION[x.uci()] for x in sorted_legal_moves]\n",
    "    legal_actions = np.array(legal_actions, dtype=np.int32)\n",
    "    legal_actions = np.expand_dims(legal_actions, axis=-1)\n",
    "    # Tokenize the return buckets.\n",
    "    dummy_return_buckets = np.zeros((len(legal_actions), 1), dtype=np.int32)\n",
    "    # Tokenize the board.\n",
    "    tokenized_fen = tokenizer.tokenize(board.fen()).astype(np.int32)\n",
    "    sequences = np.stack([tokenized_fen] * len(legal_actions))\n",
    "    # Create the sequences.\n",
    "    sequences = np.concatenate(\n",
    "        [sequences, legal_actions, dummy_return_buckets],\n",
    "        axis=1,\n",
    "    ) # [(M)oves x (S)equence Length]\n",
    "    layer_outputs, log_probs = self.predict_fn(sequences) # [M x L x S x E], [M x S x V]\n",
    "    return {\n",
    "      'layer_outputs': layer_outputs[:, :, -1], # [M x L x E]\n",
    "      'log_probs': log_probs[:, -1], # [M x V]\n",
    "      'fen': board.fen(),\n",
    "    }\n",
    "    # return {'log_probs': self.predict_fn(sequences)[:, -1], 'fen': board.fen()}\n",
    "\n",
    "  def play(self, board: chess.Board):\n",
    "    analysis = self.analyse(board)\n",
    "    return_buckets_log_probs = self.analyse(board)['log_probs']\n",
    "    return_buckets_probs = np.exp(return_buckets_log_probs)\n",
    "    win_probs = np.inner(return_buckets_probs, self._return_buckets_values)\n",
    "    _update_scores_with_repetitions(board, win_probs)\n",
    "    sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
    "    if self.temperature is not None:\n",
    "      probs = scipy.special.softmax(win_probs / self.temperature, axis=-1)\n",
    "      # return self._rng.choice(sorted_legal_moves, p=probs)\n",
    "      best_index = self._rng.choice(np.arange(len(sorted_legal_moves)), p=probs)\n",
    "    else:\n",
    "      best_index = np.argmax(win_probs)\n",
    "      # return sorted_legal_moves[best_index]\n",
    "    return sorted_legal_moves[best_index], analysis['layer_outputs'][best_index] # .., [L x E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_wrap_predict_fn(\n",
    "    predictor: constants.Predictor,\n",
    "    params: hk.Params,\n",
    "    batch_size: int = 32,\n",
    "):\n",
    "  \"\"\"Returns a simple prediction function from a predictor and parameters.\n",
    "\n",
    "  Args:\n",
    "    predictor: Used to predict outputs.\n",
    "    params: Neural network parameters.\n",
    "    batch_size: How many sequences to pass to the predictor at once.\n",
    "  \"\"\"\n",
    "  jitted_predict_fn = jax.jit(predictor.predict)\n",
    "\n",
    "  def fixed_predict_fn(sequences: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Wrapper around the predictor `predict` function.\"\"\"\n",
    "    assert sequences.shape[0] == batch_size\n",
    "    return jitted_predict_fn(\n",
    "        params=params,\n",
    "        targets=sequences,\n",
    "        rng=None,\n",
    "    )\n",
    "\n",
    "  def predict_fn(sequences: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Wrapper to collate batches of sequences of fixed size.\"\"\"\n",
    "    # sequences: [M x S]\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    remainder = -len(sequences) % batch_size\n",
    "    padded = np.pad(sequences, ((0, remainder), (0, 0))) # [(M + R) x S]\n",
    "    sequences_split = np.split(padded, len(padded) // batch_size) # [(M + R) / B x B x S]\n",
    "    all_layer_outputs, all_probs = [], []\n",
    "    for sub_sequences in sequences_split:\n",
    "      # sub_sequences: [B x S]\n",
    "      layer_outputs, probs = fixed_predict_fn(sub_sequences) # layer_outputs: [B x L x S x E], probs: [B x S x V]\n",
    "      all_layer_outputs.append(layer_outputs)\n",
    "      all_probs.append(probs)\n",
    "    layer_outputs = np.concatenate(all_layer_outputs, axis=0) # [(M + R) x L x S x E]\n",
    "    probs = np.concatenate(all_probs, axis=0) # [(M + R) x S x V]\n",
    "    # assert len(outputs) == len(padded)\n",
    "    # assert len(layer_outputs) == len(padded) #TODO: Skipping this for now\n",
    "    assert len(probs) == len(padded) \n",
    "    assert len(layer_outputs) == len(padded)\n",
    "    # return outputs[: len(sequences)]  # Crop the padded sequences.\n",
    "    # return layer_outputs[: len(sequences)], probs[: len(sequences)] #TODO: Skipping this for now\n",
    "    return layer_outputs[: len(sequences)], probs[: len(sequences)] # [M x L x S x E], [M x S x V]\n",
    "\n",
    "  return predict_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import searchless_chess.src.transformer as transformer\n",
    "import searchless_chess.src.utils as utils\n",
    "import searchless_chess.src.training_utils as training_utils\n",
    "import searchless_chess.src.engines.neural_engines as neural_engines\n",
    "import searchless_chess.src.tokenizer as tokenizer\n",
    "\n",
    "\n",
    "policy = 'action_value'\n",
    "num_layers = 16\n",
    "embedding_dim = 1024\n",
    "num_heads = 8\n",
    "num_return_buckets = 128\n",
    "output_size = num_return_buckets\n",
    "\n",
    "predictor_config = transformer.TransformerConfig(\n",
    "    vocab_size=utils.NUM_ACTIONS,\n",
    "    output_size=output_size,\n",
    "    pos_encodings=transformer.PositionalEncodings.LEARNED,\n",
    "    max_sequence_length=tokenizer.SEQUENCE_LENGTH + 2,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    embedding_dim=embedding_dim,\n",
    "    apply_post_ln=True,\n",
    "    apply_qk_layernorm=False,\n",
    "    use_causal_mask=False,\n",
    ")\n",
    "\n",
    "predictor = build_transformer_predictor_with_intermediate(config=predictor_config)\n",
    "\n",
    "_, return_buckets_values = utils.get_uniform_buckets_edges_values(\n",
    "      num_return_buckets\n",
    ")\n",
    "\n",
    "params = training_utils.load_parameters(\n",
    "    checkpoint_dir='/home/mhamza/searchless_chess/checkpoints/270M',\n",
    "    params=predictor.initial_params(\n",
    "        rng=jrandom.PRNGKey(1),\n",
    "        targets=np.ones((1, 1), dtype=np.uint32),\n",
    "    ),\n",
    "    step=6_400_000,\n",
    ")\n",
    "\n",
    "# engine = neural_engines.ENGINE_FROM_POLICY[policy](\n",
    "#   return_buckets_values=return_buckets_values,\n",
    "#   predict_fn=neural_engines.wrap_predict_fn(\n",
    "#     predictor=predictor,\n",
    "#     params=params,\n",
    "#     batch_size=1,\n",
    "#   ),\n",
    "# )\n",
    "play_engine = ActionValueDebugEngine(\n",
    "  return_buckets_values=return_buckets_values,\n",
    "  predict_fn=my_wrap_predict_fn(\n",
    "    predictor=predictor,\n",
    "    params=params,\n",
    "    batch_size=1,\n",
    "  ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 17, 79, 1024)\n",
      "(20, 17, 79, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Move.from_uci('e2e4'),\n",
       " array([[ 1.8495966e+00,  5.8102436e+00,  2.9075146e-04, ...,\n",
       "          1.6825292e+00,  7.2716112e+00,  2.5959897e-01],\n",
       "        [ 2.8245749e+00,  8.1319637e+00, -2.2196240e+00, ...,\n",
       "         -3.6888738e+00,  6.8539166e+00,  2.7591591e+00],\n",
       "        [ 4.2268257e+00,  1.2340109e+01, -2.7381961e+00, ...,\n",
       "         -9.1484380e-01,  1.6686024e+01,  4.9675984e+00],\n",
       "        ...,\n",
       "        [-1.4124680e+00, -3.0761728e+02,  1.5521661e+01, ...,\n",
       "         -1.8162535e+02, -7.5763474e+01, -4.1706543e+01],\n",
       "        [-6.3728233e+01, -2.8500610e+02,  2.9011784e+01, ...,\n",
       "         -1.1035236e+02, -5.6911602e+01, -2.2329647e+01],\n",
       "        [-8.4748864e-04, -5.3715512e-02,  1.7183146e-04, ...,\n",
       "          1.3432965e-03, -1.5181114e-03,  3.6411311e-03]], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Play a move with the agent\n",
    "import chess\n",
    "board = chess.Board()\n",
    "outputs = play_engine.play(board)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1024)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "searchless_chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
